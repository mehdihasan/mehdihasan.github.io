{"pageProps":{"author":"Mehdi Hasan","posts":[{"slug":"a-new-architecture-is-emerging-inside-the-agentic-ai-shift-in-software-engineering","title":"A New Architecture Is Emerging: Inside the Agentic AI Shift in Software Engineering","date":"2025-12-8","tags":["AI Agents","Software Engineering","Multi-Agent Systems","System Design"],"coverImage":"/images/agents/cover.jpg","author":"Mehdi Hasan","content":"\nA few days ago, I had the opportunity to attend an [**5-Day AI Agents Intensive Course with Google**](https://www.kaggle.com/learn-guide/5-day-agents) arranged by Kaggle in collaboration with Google. Today, I want to share what the course covered, what I learned, and why I believe agentic systems are going to shape the future of software development.\n\n## The Course Structure\n\nThe course was organized into **five modules across five days**, each focused on one core pillar of agentic AI development. Every day included a rich set of learning materials: a summary podcast, a detailed whitepaper, hands-on codelabs in Python using ADK, and a one-hour YouTube livestream featuring managers, engineers, and researchers from Google discussing the day’s topic. This blend of theory, practice, and expert insight made the learning experience both deep and practical.\n\n### **Day 1: Introduction to AI Agents**\n\nThe first day laid the foundation. We explored what AI agents are, why they matter, and how they differ from standalone LLM applications. Using the Agent Development Kit, we built our very first agent - and even a simple multi-agent system. It was surprisingly approachable: a bit of Python, some orchestration, and an LLM under the hood.\n\nThe accompanying whitepaper introduced a taxonomy of agent capabilities and emphasized the importance of **AgentOps**, reliability, governance, and secure interoperability using identity and constrained policies.\n\nIn the codelabs, we built a basic agent powered by Gemini, and a small multi-agent system capable of using Google Search for real-time information retrieval.\n\nThese early exercises highlighted the power of combining reasoning (LLMs) with tools and structured workflows.\n\n### **Day 2: Building Tools for Agents**\n\nDay two focused on the tool ecosystem that enables agents to act rather than just reason. We learned how [MCP](https://modelcontextprotocol.io/docs/getting-started/intro) servers and standardized protocols let agents call external APIs, retrieve real-time data, and perform actions that go beyond the LLM’s training data.\n\nThe whitepaper covered best practices for designing high-quality tools and introduced the architecture, communication layers, and enterprise-readiness considerations of MCP.\n\nIn the codelabs, we converted Python functions into tools agents could call, built custom MCP-based capabilities, and implemented long-running tool operations where an agent pauses execution and requests human approval before continuing.\n\n### **Day 3: Context Engineering**\n\nThe third module was all about giving agents **memory**, continuity, and personalization. We explored how context engineering enables agents to maintain working memory within a session and persist long-term memory across sessions - crucial for multi-step or long-running tasks.\n\nThe whitepaper introduced “Sessions” as the container for immediate conversational history and “Memory” as the persistence layer for long-term state retention.\n\nThe codelabs demonstrated how to manage conversation history in ADK, enable multi-turn reasoning, and give agents long-term memory that survives across different interactions.\n\nBy the end of the day, agents felt more like persistent digital assistants rather than single-request responders.\n\n### **Day 4: Reliability and Observability**\n\nThis module addressed one of the most important challenges in AI engineering: ensuring agents behave predictably and transparently. We explored logging, tracing, metrics, and evaluation methods to monitor agent behavior and manage costs over time.\n\nThe whitepaper presented a comprehensive evaluation framework built on:\n\n* **Logs** (the diary),\n* **Traces** (the narrative), and\n* **Metrics** (the health report),\n\nand discussed scalable evaluation techniques like LLM-as-a-Judge and Human-in-the-Loop(HITL) workflows.\n\nIn the codelabs, we learned to debug agent behavior using detailed logs and traces, understand why an agent made a particular decision, and evaluate the quality of responses and tool usage using structured scoring methods.\n\nThis day provided the essential “production mindset” needed for trustworthy deployment.\n\n### **Day 5: Production-Grade Multi-Agent Systems**\n\nThe final module brought everything together. We moved from prototypes to production-ready architecture, learning how to design scalable systems composed of multiple cooperating agents.\n\nThe whitepaper explored the operational lifecycle of enterprise-grade agents, focusing on deployment, scaling, and the **Agent2Agent (A2A) protocol**, which enables agents to communicate and collaborate directly with other agents.\n\nIn the codelabs, we: built multi-agent systems using A2A, enabled agents to exchange messages and delegate tasks, and deployed an agent to the **Vertex AI Agent Engine** to run as a scalable service on Google Cloud.\n\nThis was the moment where all the concepts matured into a clear picture of how a team of agents can function like specialized human teams - each agent doing its part to achieve a complex collective goal.\n\n## The Tech Stack Behind the Agents\n\nFrom a software engineering perspective, the technology wasn’t entirely new.\nThe course relied on:\n\n* Jupyter Notebooks\n* Python\n* MCP client–server architecture\n* API and protocol design\n* Logging, tracing, and metrics\n* Databases for storing context and memory\n\nWhat stood out as new was the ADK (Agent Development Kit). It functions much like the SDKs we’ve seen in other technology ecosystems - Android, iOS, cloud frameworks, and more. ADK provides a structured environment for defining agent behavior, attaching tools, and connecting agents to LLMs securely through API keys.\n\n## How AI Agents Actually Work\n\nLLMs, by themselves, can only reason over the information they’ve been trained on. They cannot take actions, fetch real-time data, or call external systems.\nAgents bridge this gap.\n\nThey extend an LLM’s capabilities by:\n\n* gathering fresh, real-world information through tools,\n* executing functions or programs,\n* performing calculations,\n* calling APIs,\n* searching the internet, and\n* feeding the results back into the LLM for analysis.\n\nIn this model, the **LLM acts as the reasoner** - interpreting goals, understanding context, and making decisions - while the **agent functions as the executor**, carrying out steps, coordinating tools, and managing workflows.\n\nThis separation of roles is what allows complex, multi-step, and even multi-agent systems to function reliably and continuously, far beyond what a standalone LLM can achieve.\n\n## A Practical Example: Content Creation With Agents\n\nConsider something as common as producing a full article. Traditionally, this involves several steps:\n\n1. researching the topic,\n2. gathering reference material,\n3. structuring and drafting the piece,\n4. creating visuals,\n5. editing and refining,\n6. and finally publishing it.\n\nA process like this usually demands hours of focused work - or the coordination of multiple people.\n\nWith agents, this workflow can be split into a team of specialists working together:\n\n* a **research agent** gathering reliable contemporary information,\n* a **title and SEO agent** generating headlines and keywords,\n* a **drafting agent** turning findings into structured content,\n* an **image-generation agent** creating visuals,\n* an **editor agent** refining clarity and tone,\n* and a **publishing agent** formatting and posting the final piece.\n\nEach agent has a narrow responsibility, similar to microservices in software systems. This orchestration - driven by an LLM as the “reasoner” and powered by tools as the “executors” - lets machines automate large, multi-step creative workflows with a level of coordination that was never practical before.\n\nWhat’s interesting is how this reflects a broader industry shift.\n\n## My Final Project: Smart Property Discovery\n\nFor the course project, I built a multi-agent system that helps users find housing properties matching their preferences.\n\nHere’s how it worked:\n\n* One agent scraped property data from different sources.\n* Specialized tools calculated features such as distance to the nearest station, water body, or bus stop.\n* Another agent evaluated whether a property met the client’s requirements.\n* If a property scored above a certain threshold, a notification agent emailed the user.\n\nThis solution saved significant time in manually filtering through endless property listings - a perfect example of real-world value from agentic systems.\n\n## The Future of Work: What’s About to Shift?\n\nWorking through these agent-driven workflow patterns makes it obvious how quickly automated systems are moving from experimental to foundational. I think the shift isn’t about replacing individual tasks here and there - it’s about restructuring *how* work gets done.\n\n### Where Automation Will Accelerate\n\nThe workflows denoted in the course - sequential pipelines, parallel research teams, refinement loops - highlight the kinds of tasks that are first-class for automation:\n\n* processes built on repeatable, well-defined steps,\n* information gathering that scales with volume,\n* decisions shaped by consistent rules rather than deep judgment,\n* work that benefits from predictable execution over creativity.\n\nThese are exactly the domains where agents outperform traditional manual approaches.\n\n### Roles That Will Grow, Not Shrink\n\nIn my opinion, as systems will become increasingly agentic, entirely new categories of work will emerge around:\n\n* designing and composing complex agents,\n* building custom tools and function interfaces,\n* maintaining long-running agent systems,\n* orchestrating workflows across sequential, parallel, and loop structures,\n* monitoring and debugging multi-agent pipelines.\n\nWe’re moving toward a world where “agent engineer” or “workflow orchestrator” becomes as common a title as “backend developer” is today.\n\nGiven the current trajectory, it's reasonable to expect broad adoption within the next **5–10 years**, not because AI is “taking over,” but because organizations will automate any process that can be reliably broken into agent-friendly steps. In fact, I am starting to see this happening in the organization I work for, right in front of my own eyes.\n\nFor anyone entering software development now, learning to architect and operate agent systems will be a career advantage for sure.\n\n### A New Development Ecosystem Taking Shape\n\nOne of the clearest insights from the course is that we’re watching a new platform era begin. Major companies aren’t just releasing models - they’re introducing full ecosystems for agent construction.\n\nGoogle’s stack is a prime example: the Gemini models, the [Agent Development Kit (ADK)](https://google.github.io/adk-docs/), workflow-specific agent types (Sequential, Parallel, Loop), custom tools, and orchestration layers. This ecosystemization is familiar in tech:\n\n* Android → Android SDK\n* iOS → Xcode and platform frameworks\n* Cloud → AWS/GCP/Azure\n* Web → React, Angular, Vue\n\nI guess, agentic AI will follow the same path. Each vendor will assemble its own “agent stack,” and developers will choose the one that best suits their workflows, constraints, and integration needs - much like selecting a cloud provider or web framework today.\n\nWe’re still early in this shift, but the competition and cross-pollination that follow will shape how agent systems are built for years to come.\n\n### The Foundations Still Matter\n\nEven as agents automate more of the surface-level work, the underlying engineering remains critical. Everything demonstrated in the course - passing state between agents, controlling execution order, managing tools, and handling refinement loops - depends on reliable systems beneath the surface.\n\nCore skills still form the backbone - algorithms and data structures, database and API design distributed system fundamentals, reliability engineering, performance optimization etc.\n\nAgents can coordinate workflows, but they still rely on well-architected infrastructure, predictable interfaces, and resilient systems. The fundamentals aren’t being replaced - they remain the bedrock that makes large-scale agentic automation possible.\n\n## Final Thoughts\n\nOverall, the Agentic AI course by Google on the Kaggle platform was incredibly insightful. It gave me a practical understanding of how agentic systems operate, how the ecosystem is evolving, and what software development might look like in the near future.\n\nI walked away not just with new skills, but with a new perspective on how AI agents will transform workflows, industries, and our roles as developers.\n"},{"slug":"is-something-dramatic-happening-underground-in-bangladesh","title":"Is Something Dramatic Happening Underground in Bangladesh? A Data-Based Look at Earthquakes","date":"2025-12-04","tags":["Data","Science"],"coverImage":"/images/eqb/earthquake_animation.gif","author":"Mehdi Hasan","content":"\nRecent weeks have raised public concern in Bangladesh after several noticeable earthquakes shook the Dhaka–Narsingdi region. Many people are wondering: *Is this the start of something dangerous? Has seismic activity suddenly increased?* To answer these questions, we analyzed decades of earthquake data across Bangladesh and compared it with the events of 2025. Here is what the numbers — not rumors — actually show.\n\n## **What the long-term data tells us**\n\nA full historical catalog of 465 earthquakes (1976–2025) shows that Bangladesh experiences regular moderate seismicity. The recent activity sits within long-term patterns, but several features of **2025 stand out scientifically**:\n\n### **Energy release in 2025 is higher than average**\n\nThis year’s events have released about **1.65× more seismic energy** than the historical yearly average. That increase is driven mainly by the **M5.4 earthquake on November 21**, the largest event of the year.\n\n![img](/images/eqb/seismic_eng_per_yr.png)\n\n### **Event counts are *not* unusually high**\n\nStatistical tests show that **2025 has a normal number of earthquakes** — no spike in the *frequency* of events.\n\n![img](/images/eqb/e_count.png)\n\n### **Magnitudes remain in the typical range**\n\nThe distribution of earthquake magnitudes in 2025 does **not differ significantly** from previous decades.\n\n![img](/images/eqb/mag_distribution.png)\n\n![img](/images/eqb/mag_bin.png)\n\n### **Depth is where things get interesting**\n\nMultiple tests show that **2025 earthquakes are noticeably shallower** than in most previous years. Shallow earthquakes are felt more strongly at the surface, even if their magnitudes are moderate.\n\n![img](/images/eqb/median_quake_depth.png)\n\nThis is one of the most important findings: **No unusual increase in the number of earthquakes — but the ones occurring are shallower, so they feel stronger.**\n\n![img](/images/eqb/depth_dis.png)\n\n## **Understanding the recent sequence near Dhaka / Narsingdi**\n\nSo far, four earthquakes attracted public attention in late November and early December:\n\n| Date (UTC) | Mag | Depth | Location        |\n|------------|-----|-------|-----------------|\n| Nov 21     | 5.4 | 27 km | Narsingdi (SSW) |\n| Nov 22     | 4.3 | 10 km | Narsingdi (W)   |\n| Nov 27     | 4.0 | 10 km | Tungi (NNE)     |\n| Dec 4      | 4.1 | 10 km | Dhaka (ESE)     |\n\nThe **21 November M5.4 earthquake** is almost certainly the **mainshock**, assuming no larger event occurred shortly before or after it. Terms like *mainshock* or *foreshock* are assigned **after** the fact, once the full sequence is known. The three subsequent earthquakes — magnitudes **4.0 to 4.3** over the following two weeks — fit the pattern of **aftershocks**, which is the normal and expected response of the crust after a moderate event like this.\n\nAftershock models and cluster analysis support this:\n\n- Spatially close\n- Shallow\n- Occurred soon after the M5.4\n- Magnitudes appropriate for aftershocks\n\nThere is **no scientific indication** that the sequence is an \"ongoing mega-event\" or a sign of an imminent major catastrophe.\n\n![img](/images/eqb/quake_clusters.png)\n\n## **Should people be worried?**\n\n### **Short answer: No panic — but yes, be prepared.**\n\nBased on the data:\n\n- There is **no evidence** of a large earthquake building up in the immediate future.\n- The pattern fits a **normal mainshock–aftershock sequence**.\n- Bangladesh’s long-term seismic environment is active, but this year is not unprecedented.\n\nThat said, shallow earthquakes, even at moderate magnitudes, can **shake cities hard**, especially in cities like Dhaka with probably thousands of vulnerable buildings. This means:\n\n- **Risk exists**\n- **But it is manageable**\n- **Preparedness is the key difference-maker**\n\n## **Why shallow earthquakes matter more**\n\nOur analysis found a statistically significant shift toward shallower depths in 2025. This is important because:\n\n- A shallow M4–M5 can feel like a deeper M6 in terms of surface shaking.\n- Dhaka has many old and unreinforced structures that are more sensitive to this kind of shaking.\n- Even without a major earthquake, shallow moderate events can cause injuries, wall collapses, and infrastructure disruption.\n\nSo the message is not \"a big earthquake is coming.\"\nThe message is: **a moderate earthquake can still be damaging if buildings are fragile — so strengthen preparedness now.**\n\n## **What people and communities can do right now**\n\n### **A. Stay informed without panic**\n\nFollow official bulletins from:\n\n- Bangladesh Meteorological Department (BMD)\n- National Disaster Response agencies\n- Universities or credible institutions\n\n**Please avoid unverified social media rumors.**\n\n### **B. Community organization**\n\n- Form **local volunteer preparedness groups** in neighborhoods.\n- Identify safe open spaces.\n- Help elderly or disabled neighbors with emergency planning.\n- Practice evacuation routes.\n\n### **C. Training and drills**\n\nPush local authorities and community leaders to:\n\n- Organize **earthquake safety workshops**.\n- Conduct **drop–cover–hold-on drills** in schools, offices, and markets.\n- Teach people how to check homes for hazards (loose shelves, falling objects, unsecured gas cylinders).\n\n### **D. Structural safety**\n\nCitizens and journalists should push authorities to:\n\n- Enforce building codes more strictly.\n- Inspect vulnerable buildings, especially schools and hospitals.\n- Provide public guidance on strengthening old structures.\n\n### **E. Spread helpful information**\n\nLocal organizations can print simple, factual pamphlets covering:\n\n- What to do during shaking\n- How to prepare emergency kits\n- Where to gather after an earthquake\n- How aftershocks behave\n- What NOT to believe on social media\n\nHelping people understand what is normal in an earthquake sequence reduces fear — and that improves safety.\n\n## **Final takeaway**\n\n**No, Bangladesh is not currently experiencing a dramatic, unprecedented seismic crisis.**\nBut **yes**, 2025’s earthquakes — especially the shallow M5.4 near Narsingdi — remind us that Bangladesh sits in an active tectonic region where moderate earthquakes can be strongly felt.\n\n- The number of earthquakes is normal.\n- Magnitudes are normal.\n- **Depths are shallower**, so shaking feels stronger.\n- The recent events fit a **mainshock–aftershock pattern**.\n- Preparedness, not panic, is the appropriate response.\n\nEarthquakes cannot be stopped, but **knowledge, training, and readiness** can prevent injuries and save lives. The best time to prepare is **before** a larger earthquake happens — and these recent events give Bangladesh a valuable opportunity to do exactly that.\n\nFor those interested in the full analysis, code, and data, it is available on [this GitHub repository](https://github.com/mehdihasan/bd-earthquake-analysis-2025).\n\n## Verified Sources Covering 2025 Earthquake\n\n1. [No, Dhaka Is Not At Risk of a 9.0 Earthquake That Would Liquefy the City](https://counterpointbd.substack.com/p/no-dhaka-is-not-at-risk-of-a-90-earthquake) by Asifur Rahman Khan\n2. [The Latest Earthquake Was a Warning Sign: Bangladesh Isn’t Ready](https://thediplomat.com/2025/12/the-latest-earthquake-was-a-warning-sign-bangladesh-isnt-ready) by Thomas L. Davis\n"},{"slug":"fixing-concurrent-queries-within-the-same-session-in-clickHouse-async-python-apps","title":"Fixing Concurrent Queries Within the Same Session in ClickHouse Async Python Apps (Uvicorn + FastAPI)","date":"2025-10-16","tags":["Python","ClickHouse","Uvicorn","Concurrency","Architecture","DevOps"],"coverImage":"/images/ch1/cover.jpg","author":"Mehdi Hasan","content":"\nConnecting to a database from Python seems simple enough - you create a client, send queries, and handle results. But when we scaled that to thousands of concurrent requests under an async web server, things got a bit more interesting.\n\nThis post walks through how we hit a classic concurrency issue in our ClickHouse integration - how it appeared, what caused it, the quick fix we applied, and finally how we designed a long-term scalable solution using an async connection pool.\n\n## The Setup\n\nOur backend service is a data ingestion API that pushes concurrent large JSON payloads into ClickHouse. It runs on top of [**Uvicorn**](https://uvicorn.dev/), an ASGI web server that handles requests asynchronously.\n\nWe used the official [clickhouse-connect](https://github.com/ClickHouse/clickhouse-connect) library to communicate with the database. In the beginning, the design looked clean and simple:\n\n```python\n# Simplified version of the initial design\n\nclass CB:\n\n    def __init__(self):\n        self.client = AsyncClient(\n            host=\"clickhouse_host\",\n            port=8123,\n            database=\"DB_NAME\",\n            username=\"default\",\n            password=\"default\"\n        )\n\n    async def post_raw(self, payload):\n        await self.client.insert(table=\"m_data\", data=payload)\n```\n\nWe created **a single AsyncClient instance** when the backend started - a singleton pattern. Every request reused this same client to perform queries, inserts and health checks.\n\nWe leveraged [ClickHouse's server-side asynchronous insert](https://clickhouse.com/docs/optimize/asynchronous-inserts) feature by configuring the insertion settings to use ***async_insert=1***. This setting is key for high-throughput ingestion, as it tells the [ClickHouse server to buffer and batch data internally](https://clickhouse.com/blog/asynchronous-data-inserts-in-clickhouse). However, as we soon discovered, server-side data handling being asynchronous does not guarantee client-side session safety.\n\n## The Problem Appears\n\nEverything was smooth in development and staging environments. It looked fine - until we hit production and started ingesting thousands of rows per minute, the logs exploded with the following message:\n\n> ***Attempt to execute concurrent queries within the same session. Please use a separate client instance per thread/process.***\n\nThirty percent of the inserts began failing randomly under load. Some succeeded, others didn't. It wasn't deterministic - but it was bad.\n\n## The Role of Uvicorn and Async Concurrency\n\nOur API application runs on **Uvicorn** web server, which means requests are handled *asynchronously* on a single [event loop](https://uvicorn.dev/concepts/event-loop/) by the [*uvloop* library](https://github.com/MagicStack/uvloop).\n\nIn async Python, multiple [coroutines](https://docs.python.org/3/library/asyncio-task.html) (i.e., concurrent requests) share the same event loop and can all run at once when waiting on I/O. So even though we weren't using multiple OS threads (no parallelism), we achieved high concurrency within the same single-threaded process by efficiently switching between waiting requests.\n\nHere's what was happening under the hood:\n\n![img](/images/ch1/image_1.jpg)\n\nBecause all requests used the **same Clickhouse AsyncClient instance**, multiple coroutines tried to send different queries over the same underlying TCP session - at the same time. This scenario is a classic example of shared mutable state in an asynchronous environment. Multiple requests raced to use the same underlying socket before the previous query had finished, violating the database client's contract.\n\nClickHouse rightfully rejected this pattern. Its client session protocol doesn't support multiple concurrent queries per connection. Each query must complete before another begins on the same connection.\n\nIt's important to distinguish between ClickHouse's server-side asynchronous insert feature (async_insert=1) and our client-side asynchronous concurrency (Uvicorn/coroutine model). The server-side feature efficiently buffers the data. However, the client driver still requires a non-conflicting network session to send the insert request and receive the response (even if that response is a quick acknowledgement). Our problem was that multiple coroutines were attempting to initiate their separate insert operations over the single shared client session at the exact same moment, which the client/session protocol disallowed. The fix was necessary to resolve the session-level concurrency issue, not the server's data-buffering mechanism.\n\nThat's why the error message said:\n\n> ***Please use a separate client instance per thread/process.***\n\nEven though we weren't using multiple threads, we had the same effect: concurrent use of a shared connection.\n\n## Quick Fix: One Client per Request\n\nWhen production fire alarms are ringing, elegance comes second.\n\nAs a **quick fix**, we changed our approach to create a **new ClickHouse client per request**.\n\n```python\nasync def post_data(self, payload):\n    async with AsyncClient(client=get_client(...)) as client:\n        await client.insert(...)\n```\n\nThat immediately solved the concurrency issue. Each request had its own isolated client - and therefore its own TCP session - avoiding shared-state problems completely.\n\nBut this (and probably most) quick solution came at a cost.\n\nCreating and closing a ClickHouse client for every single request is expensive. At large ingestion volumes, it increases connection setup overhead, authentication latency, and CPU churn on both the client and server sides.\n\nWe needed something more efficient.\n\n## The Final Fix: Connection Pooling\n\nOnce stability returned, we revisited the design.\n\nInstead of one global client or one-per-request, we moved to a **connection pool** - maintaining a fixed number of ready-to-use ClickHouse clients and reusing them efficiently.\n\n![img](/images/ch1/image_2.jpg)\n\n### New approach\n\n```python\nclass PooledClient:\n    \"\"\"Helper Context Manager Class\"\"\"\n\n    def __init__(self, pool, client):\n        self._pool = pool\n        self.client = client\n\n    async def __aenter__(self):\n        \"\"\"Called when 'async with' starts\"\"\"\n        return self.client\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"\n        Called when 'async with' block ends (even on error).\n        For simplicity, we just return the client to the pool.\n        (You could add logic here to replace broken clients.)\n        \"\"\"\n        if not getattr(self.client, \"is_closed\", False):\n            await self._pool.put(self.client)\n        return False\n\n\nclass ClickhousePool:\n    \"\"\"Main Connection Pool Class\"\"\"\n\n    def __init__(self):\n        self._pool = asyncio.Queue(maxsize=SIZE)\n        for _ in range(SIZE):\n            client = AsyncClient(client=get_client(...))\n            self._pool.put_nowait(client)\n\n    async def get_client(self):\n        \"\"\"Returns a context manager object that handles the client lifecycle\"\"\"\n        return PooledClient(self._pool, await self._pool.get())\n\n    async def post_data(self, payload):\n        \"\"\"The Clean Consumption in the API\"\"\"\n        rows = ...  # transformations of payload\n        table_name = ...\n        columns = ...\n\n        async with self.get_client() as client:\n            await client.insert(\n                table=table_name,\n                data=rows,\n                column_names=columns,\n                settings={\n                    'async_insert': 1,\n                    'wait_for_async_insert': 0,\n                    # ... other settings\n                }\n            )\n```\n\nOnce the connection pool is in place, usage of async API is straightforward:\n\n```python\ncp = ClickhousePool()\nawait cp.post_data(payload)\n```\n\nWith the pooled design we make sure that, (1) each of the requests borrow a client from the pool, (2) they use it to execute a query or insert, (3) the client is released back into the pool afterward, (4) if a client breaks (due to a network or protocol error), it's replaced with a new one.\n\nThis hybrid approach provides safety by not sharing clients across concurrent requests, performance by avoiding recreate clients repeatedly, scalability by easily tune pool size to match workload.\n\n```txt\nSingleton        ->  One global AsyncClient\nPer-request      ->  New client per request\nConnection pool  ->  Limited shared pool, reused safely\n```\n\n## Validation and Results\n\nOnce deployed, the difference was clear.\n\nWe validated the new behavior in three ways. Error messages related to ***concurrent queries within the same session*** disappeared completely. Connection metrics stabilized - fewer reconnections, more consistent query latencies. The ClickHouse row count graphs started growing linearly again - confirming ingestion pipelines were back to full capacity.\n\n## Lessons Learned\n\nOne of the key takeaways from this experience was realizing that asynchronous code isn't automatically thread-safe or concurrency-safe. Using async functions doesn't guarantee that shared resources can be accessed safely by multiple coroutines. In our case, reusing a single AsyncClient across concurrent requests seemed fine at first, but when multiple coroutines tried to use it simultaneously, it led to unexpected failures. The event loop can rapidly switch between these coroutines, and if the underlying resource isn't designed for concurrent access, it will eventually break - exactly as we saw with the ClickHouse client.\n\nWe also learned that Uvicorn's speed comes from concurrency, not parallelism. It multiplexes many requests on a single event loop in one process. That means even though the server feels lightweight and fast, all those requests are sharing the same runtime environment. Any global object - such as a database connection, HTTP session, or cache client - must be carefully managed to ensure it's concurrency-safe. The illusion of simplicity in async code can be deceptive; behind the scenes, coroutines are continuously yielding and resuming, which magnifies issues caused by shared mutable state.\n\nWhen production problems strike, it's often tempting to apply quick fixes to restore stability. We did the same by creating one client per request - a brute-force but effective short-term solution. It isolated each operation and immediately eliminated concurrency conflicts. However, that approach didn't scale well. Each new client meant an additional connection handshake, authentication cycle, and network setup overhead. It worked to stop the bleeding, but it wasn't efficient enough for a high-throughput ingestion system. A connection pool, on the other hand, gave us the right balance - isolation without excessive overhead.\n\nFinally, this journey reinforced that observability is critical. Without clear logs, metrics, and dashboards, it would have been nearly impossible to pinpoint the root cause or verify the effectiveness of our fix. Our Grafana dashboards, error logs, and ClickHouse ingestion metrics made it clear when the issue appeared, how severe it was, and how things stabilized after deploying the pooled solution. Good observability turned what could have been a long debugging marathon into a structured diagnosis and validation process.\n\n## Closing Thoughts\n\nThis issue was a great reminder that even high-level async code hides some deep concurrency challenges underneath.\n\nThe evolution - from a single shared client, to per-request isolation, to an efficient async connection pool - illustrates how understanding the **runtime model** (Uvicorn + async I/O) is just as important as writing correct business logic.\n"}]},"__N_SSG":true}